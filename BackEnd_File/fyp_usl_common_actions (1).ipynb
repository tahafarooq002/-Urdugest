{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da2921c9-65c7-4fb7-b8cb-18e40715a7ae",
   "metadata": {},
   "source": [
    "**preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db872254-4cb7-4a7b-a22a-577fd2984733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import mediapipe as mp\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061a9d57-49e4-4fec-9225-14fb6a7f888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91f6d2b3-8207-4aa5-bf36-a972203823f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"./usl_common_actions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cca6e71-76c4-451d-947a-861eb74b5718",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38097c76-fcd1-4090-b4cf-62ea1fcac373",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tahaf\\anaconda3\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "                \n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = hands.process(img_rgb)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "\n",
    "                    x_.append(x)\n",
    "                    y_.append(y)\n",
    "\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x - min(x_))\n",
    "                    data_aux.append(y - min(y_))\n",
    "\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58756fa7-0617-4f6d-90db-c5a0d09343df",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('common_actions.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d61106cd-2474-4ede-b451-c843b141fcd2",
   "metadata": {},
   "source": [
    "**model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbd3a21f-2164-435c-9f7f-7e2c712cb018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b25239c9-d960-40e7-a8f3-f57a199f3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open('./common_actions.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bba8de5-1663-4fb6-b399-b223b3e84cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data Shape: (700, 42)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming data_dict['data'] contains sequences of varying lengths\n",
    "data_list = data_dict['data']\n",
    "\n",
    "# Find the maximum length among all sequences\n",
    "max_length = max(len(item) for item in data_list)\n",
    "\n",
    "# Pad sequences with zeros (or another value) to make them uniform\n",
    "padded_data = np.array([np.pad(item, (0, max_length - len(item)), mode='constant') for item in data_list])\n",
    "\n",
    "# Resulting uniform NumPy array\n",
    "print(\"Merged Data Shape:\", padded_data.shape)\n",
    "\n",
    "labels = np.asarray(data_dict['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95b7fff9-6bbb-49af-8329-0bfb2e0edf69",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = labels != 'Help'\n",
    "filtered_data = padded_data[mask]\n",
    "filtered_labels = labels[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fe108bcc-6e7c-4a3d-82a7-75a729ca3491",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(filtered_data, filtered_labels, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99985560-822b-406d-ab9b-d85053bd3654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'help': 100, 'i love you': 100, 'no': 100, 'please': 100, 'thank you': 100, 'yes': 100, 'you': 100}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "label_distribution = dict(zip(unique, counts))\n",
    "print(label_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86274d6b-84c7-47ed-b8ee-6634f265e215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        help       1.00      1.00      1.00        21\n",
      "  i love you       1.00      1.00      1.00        21\n",
      "          no       1.00      1.00      1.00        15\n",
      "      please       1.00      1.00      1.00        19\n",
      "   thank you       1.00      1.00      1.00        26\n",
      "         yes       1.00      1.00      1.00        20\n",
      "         you       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00       140\n",
      "   macro avg       1.00      1.00      1.00       140\n",
      "weighted avg       1.00      1.00      1.00       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=20, max_depth=2, random_state=42)\n",
    "model.fit(x_train, y_train)\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6fee3e51-5744-4a03-b989-78c71d5abc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100.0%\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "y_predict = model.predict(x_test)\n",
    "\n",
    "score = accuracy_score(y_predict, y_test)\n",
    "print('Accuracy: {}%'.format(score * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed4de0f9-57c8-4182-afc5-03928a684510",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('usl_common_actions.p', 'wb')\n",
    "pickle.dump({'model': model}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddcabfb-730b-48f1-ba61-0cb0cd89961a",
   "metadata": {},
   "source": [
    "**Detection check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7f7024e-8ff4-4180-9869-1a9453dacc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing test.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test.py\n",
    "# Import necessary libraries\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import cv2\n",
    "from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "with open('usl_common_actions.p', 'rb') as f:\n",
    "    model = pickle.load(f)['model']\n",
    "\n",
    "# Urdu translations for common phrases\n",
    "labels_dict = {\n",
    "    'help': 'ŸÖ€åÿ±€å ŸÖÿØÿØ ⁄©ÿ±Ÿà',\n",
    "    'i love you': 'ŸÖ€å⁄∫ ÿ¢Ÿæ ÿ≥€í Ÿæ€åÿßÿ± ⁄©ÿ±ÿ™ÿß/⁄©ÿ±ÿ™€å €ÅŸà⁄∫',\n",
    "    'no': 'ŸÜ€Å€å⁄∫',\n",
    "    'please': 'ÿ®ÿ±ÿß€Å ŸÖ€Åÿ±ÿ®ÿßŸÜ€å',\n",
    "    'thank you': 'ÿ¢Ÿæ ⁄©ÿß ÿ¥⁄©ÿ±€å€Å',\n",
    "    'yes': '€Åÿß⁄∫',\n",
    "    'you': 'ÿ¢Ÿæ'\n",
    "}\n",
    "# Set up Streamlit page configuration\n",
    "st.set_page_config(page_title=\"Urdu Sign Language\", page_icon=\"üëã\")\n",
    "st.title(\"Urdu Sign Language Recognition\")\n",
    "st.write(\"Press the button below to start recognizing Sign Language\")\n",
    "\n",
    "# Load Mediapipe Hands model\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Streamlit video capture function\n",
    "def process_video():\n",
    "    cap = cv2.VideoCapture(0, cv2.CAP_DSHOW)\n",
    "    stframe = st.empty()  # Placeholder for video frames\n",
    "    result_box = st.empty()  # Placeholder for predicted results\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            st.warning(\"Could not access the webcam.\")\n",
    "            break\n",
    "\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = hands.process(frame_rgb)\n",
    "\n",
    "        data_aux = []\n",
    "        x_ = []\n",
    "        y_ = []\n",
    "\n",
    "        if results.multi_hand_landmarks:\n",
    "            \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    x_.append(lm.x)\n",
    "                    y_.append(lm.y)\n",
    "\n",
    "                for lm in hand_landmarks.landmark:\n",
    "                    data_aux.append(lm.x - min(x_))\n",
    "                    data_aux.append(lm.y - min(y_))\n",
    "\n",
    "                    # Ensure only 42 features (21 landmarks * 2)\n",
    "                    data_aux = data_aux[:42]\n",
    "\n",
    "                x1 = int(min(x_) * frame.shape[1]) - 10\n",
    "                y1 = int(min(y_) * frame.shape[0]) - 10\n",
    "\n",
    "            \n",
    "                # Predicting the character\n",
    "                prediction = model.predict([np.asarray(data_aux)])\n",
    "                predicted_character = prediction[0]\n",
    "                predicted_urdu_character = labels_dict.get(predicted_character, \"Unknown\")\n",
    "\n",
    "                # Update the result box with the predicted Urdu character\n",
    "                result_box.text(f\"Predicted Urdu Character: {predicted_urdu_character}\")\n",
    "\n",
    "                # Draw bounding box and label\n",
    "                x1 = int(min(x_) * frame.shape[1]) - 10\n",
    "                y1 = int(min(y_) * frame.shape[0]) - 10\n",
    "                x2 = int(max(x_) * frame.shape[1]) + 10\n",
    "                y2 = int(max(y_) * frame.shape[0]) + 10\n",
    "\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
    "\n",
    "                # Create a PIL image from the OpenCV frame\n",
    "                pil_image = Image.fromarray(frame)\n",
    "                draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "                # Load your Urdu font (make sure to provide the correct path to your font file)\n",
    "                font_path = './Jameel Noori Nastaleeq Kasheeda.ttf'  # Update this path if necessary\n",
    "                font = ImageFont.truetype(font_path, 50)\n",
    "\n",
    "                # Draw the predicted Urdu character\n",
    "                #draw.text((x1, y1 - 50), predicted_urdu_character, font=font, fill=(0, 0, 0))\n",
    "\n",
    "                # Convert PIL image back to OpenCV format\n",
    "                frame = np.array(pil_image)\n",
    "\n",
    "        # Display the processed video frame\n",
    "        stframe.image(frame, channels=\"BGR\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "# Start the video processing function\n",
    "if st.button(\"Start\"):\n",
    "    process_video()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd8e9cb-521b-416f-bbd6-1ac24ee7ab54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!streamlit run test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
