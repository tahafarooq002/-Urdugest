## Urdugest

Urdugest is an AI-powered Urdu Sign Language recognition system. It detects Urdu alphabets from hand gestures and forms complete words in real-time, helping bridge communication for Urdu sign language users.

## Project StructureUrdugest â€“ Urdu Sign Language Recognition

![Python](https://img.shields.io/badge/python-3.8%2B-blue)
![License](https://img.shields.io/badge/Urdugest-green)
![Status](https://img.shields.io/badge/Project-Active-brightgreen)
![Platform](https://img.shields.io/badge/Platform-Jupyter%20Notebook-orange)



Urdugest is an AI-powered system that recognizes Urdu Sign Language (PSL) gestures and converts them into Urdu text in real-time. It detects alphabets, predicts words, and helps bridge communication gaps.

## ğŸš€ Features

#âœ‹ Urdu Sign Detection â€“ Detect hand gestures for Urdu alphabets

ğŸ§¹ Preprocessing Pipeline â€“ Resize, normalize, augment images

ğŸ¤– AI Prediction â€“ Recognize alphabets using CNN/LSTM/Transformer

ğŸ“ Word Formation â€“ Combine predicted alphabets into words

ğŸ“Š Visualization & Logging â€“ See predictions and model outputs

ğŸ““ Fully implemented in: src/main.py, notebooks/demo.ipynb

## ğŸ› ï¸ Technologies Used
Tool	Purpose
Python	Main programming language
PyTorch	Model training & inference
OpenCV	Image processing & preprocessing
NumPy / Pandas	Computation & data handling
Matplotlib / Seaborn	Visualization
Jupyter Notebook	Experiments and demo
## ğŸ“ Project Structure
Urdugest/
â”‚
â”œâ”€â”€ data/                   # Original & preprocessed datasets
â”‚   â”œâ”€â”€ raw/                # Raw PSL dataset
â”‚   â”œâ”€â”€ processed/          # Resized, normalized, augmented
â”‚   â””â”€â”€ README.md           # Dataset details
â”‚
â”œâ”€â”€ src/                    # Source code
â”‚   â”œâ”€â”€ main.py             # Entry point
â”‚   â”œâ”€â”€ train.py            # Training script
â”‚   â”œâ”€â”€ predict.py          # Prediction script
â”‚   â”œâ”€â”€ model.py            # Model definitions
â”‚   â”œâ”€â”€ preprocess.py       # Preprocessing functions
â”‚   â””â”€â”€ utils.py            # Helper functions
â”‚
â”œâ”€â”€ models/                 # Trained models & checkpoints
â”‚   â””â”€â”€ README.md
â”‚
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”‚   â”œâ”€â”€ exploratory.ipynb
â”‚   â””â”€â”€ demo.ipynb
â”‚
â”œâ”€â”€ tests/                  # Unit tests
â”‚   â”œâ”€â”€ test_main.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ scripts/                # Helper scripts (e.g., dataset download)
â”œâ”€â”€ assets/                 # Logo, sample input/output
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ .gitignore

## â–¶ï¸ How to Run
## 1ï¸âƒ£ Install Dependencies
```bash
pip install -r requirements.txt
```
## 2ï¸âƒ£ Run Training

```bash
python src/train.py
```
## 3ï¸âƒ£ Predict on New Image or Video
```bash
python src/predict.py --image path_to_image
```
## 4ï¸âƒ£ Run Main Program
```bash
python src/main.py
```
##ğŸ’¡ Example Pipeline

Load image/video of hand gestures

Detect hand signs

Preprocess the image (resize, normalize, augment)

Predict alphabet using trained AI model

Form complete word from predicted alphabets

Display results

## ğŸ› ï¸ Future Improvements

Deep learning gesture detection (YOLO, MediaPipe)

Real-time webcam support with low latency

Custom dataset expansion & augmentation

Multi-language support for regional sign languages

Unit tests & CI/CD workflow

requirements.txt â€“ All Python dependencies.
